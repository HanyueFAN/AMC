{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3e2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cacd0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ajayiidowu/PycharmProjects/pythonProject1/data/logged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8afce9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['I/Q Data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27254e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Frequency', 'Signal Strength', 'Modulation', 'Bandwidth',\n",
       "       'Location', 'Device Type', 'Antenna Type', 'Temperature', 'Humidity',\n",
       "       'Wind Speed', 'Precipitation', 'Weather Condition', 'Interference Type',\n",
       "       'Battery Level', 'Power Source', 'CPU Usage', 'Memory Usage',\n",
       "       'WiFi Strength', 'Disk Usage', 'System Load', 'Latitude', 'Longitude',\n",
       "       'Altitude(m)', 'Air Pressure', 'Device Status', 'I/Q Data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fa9f00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp             object\n",
       "Frequency              int64\n",
       "Signal Strength        int64\n",
       "Modulation            object\n",
       "Bandwidth              int64\n",
       "Location              object\n",
       "Device Type           object\n",
       "Antenna Type          object\n",
       "Temperature            int64\n",
       "Humidity               int64\n",
       "Wind Speed             int64\n",
       "Precipitation        float64\n",
       "Weather Condition     object\n",
       "Interference Type     object\n",
       "Battery Level        float64\n",
       "Power Source            bool\n",
       "CPU Usage            float64\n",
       "Memory Usage         float64\n",
       "WiFi Strength          int64\n",
       "Disk Usage           float64\n",
       "System Load          float64\n",
       "Latitude             float64\n",
       "Longitude            float64\n",
       "Altitude(m)          float64\n",
       "Air Pressure         float64\n",
       "Device Status         object\n",
       "I/Q Data              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8a384",
   "metadata": {},
   "source": [
    "# Function to convert complex numbers in string format to a pair of real-valued arrays\n",
    "def complex_str_to_real_array(complex_str):\n",
    "    # Convert the string representation to a list of complex numbers\n",
    "    complex_list = np.array(literal_eval(complex_str), dtype=np.complex64)\n",
    "    # Separate the real and imaginary parts\n",
    "    real_parts = np.real(complex_list)\n",
    "    # Concatenate the real and imaginary parts along the last axis\n",
    "    real_mean = np.mean(real_parts, axis=0)\n",
    "    return real_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b190b2",
   "metadata": {},
   "source": [
    "# Function to convert complex numbers in string format to a pair of real-valued arrays\n",
    "def complex_str_to_imag_array(complex_str):\n",
    "    # Convert the string representation to a list of complex numbers\n",
    "    complex_list = np.array(literal_eval(complex_str), dtype=np.complex64)\n",
    "    # Separate the real and imaginary parts\n",
    "    imag_parts = np.imag(complex_list)\n",
    "    # Concatenate the real and imaginary parts along the last axis\n",
    "    imag_mean = np.mean(imag_parts, axis=0)\n",
    "    return imag_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "baa077f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert complex numbers in string format to a pair of real-valued arrays\n",
    "def complex_str_to_concat_array(complex_str):\n",
    "    # Convert the string representation to a list of complex numbers\n",
    "    complex_list = np.array(literal_eval(complex_str), dtype=np.complex64)\n",
    "    # Separate the real and imaginary parts\n",
    "    abs_value = np.abs(complex_list)\n",
    "    phase_value = np.angle(complex_list)\n",
    "    # Concatenate the real and imaginary parts along the last axis\n",
    "    concatenate = np.concatenate((abs_value,phase_value)).reshape(-1,order='F')\n",
    "    return concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d338272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df['I/Q Data'].apply(complex_str_to_concat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e653f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.DataFrame(df_concat.explode().values.reshape (109324,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277f4ba",
   "metadata": {},
   "source": [
    "df_IQ_real2 = df_IQ_real2.rename(columns={'I/Q Data' : 'I/Q Real'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669f71f",
   "metadata": {},
   "source": [
    "df_IQ_imag2 = df_IQ_imag2.rename(columns={'I/Q Data' : 'I/Q Imag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d408c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop('I/Q Data', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d656166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41f8874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Device Type','Antenna Type','Interference Type','Device Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0b19fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['Frequency','Signal Strength','Bandwidth','WiFi Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2f1e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_num = df_new[num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04fbdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "df_new_num = scaler2.fit_transform(df_new_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db51e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_num = pd.DataFrame(df_new_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4fa61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_num_comb = pd.concat([df_new_num, df_concat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71315bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109324, 204)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_num_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e180233",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_new_num_comb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ddc6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109324, 204)\n"
     ]
    }
   ],
   "source": [
    "print(X_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "552e6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Modulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee437844",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in cat_columns:\n",
    "    df[cat_columns] = df[cat_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8282ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp              object\n",
       "Frequency             float64\n",
       "Signal Strength       float64\n",
       "Modulation             object\n",
       "Bandwidth             float64\n",
       "Location               object\n",
       "Device Type          category\n",
       "Antenna Type         category\n",
       "Temperature             int64\n",
       "Humidity                int64\n",
       "Wind Speed              int64\n",
       "Precipitation         float64\n",
       "Weather Condition      object\n",
       "Interference Type    category\n",
       "Battery Level         float64\n",
       "Power Source             bool\n",
       "CPU Usage             float64\n",
       "Memory Usage          float64\n",
       "WiFi Strength         float64\n",
       "Disk Usage            float64\n",
       "System Load           float64\n",
       "Latitude              float64\n",
       "Longitude             float64\n",
       "Altitude(m)           float64\n",
       "Air Pressure          float64\n",
       "Device Status        category\n",
       "I/Q Data               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71a840",
   "metadata": {},
   "source": [
    "df['Device Type'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2147a7",
   "metadata": {},
   "source": [
    "df['Interference Type'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a31cc",
   "metadata": {},
   "source": [
    "df['Antenna Type'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711cd11",
   "metadata": {},
   "source": [
    "df['Device Status'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9066a",
   "metadata": {},
   "source": [
    "df['Interference Type'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "913ae8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "975ae0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Device Type'] = label_encoder.fit_transform(df['Device Type'])\n",
    "\n",
    "df['Interference Type'] = label_encoder.fit_transform(df['Interference Type'])\n",
    "\n",
    "df['Antenna Type'] = label_encoder.fit_transform(df['Antenna Type'])\n",
    "\n",
    "df['Device Status'] = label_encoder.fit_transform(df['Device Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82a711bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Device Type, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Device Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acb404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = df['Modulation'].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80ee13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False).fit(data_label.reshape(-1, 1))\n",
    "\n",
    "data_label = ohe.transform(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4046ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109324, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9771ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical = df[cat_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a9532d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109324, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23826f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_reshape=np.vstack(data_features_reshape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "03975596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_test=np.vstack(X_numerical).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f45511c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109324, 204)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25ba14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_test2 = torch.from_numpy(X_numerical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04c1acae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([109324, 204])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4704fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109324, 204)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "42b7001a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T09:12:20.535077500Z",
     "start_time": "2023-11-09T09:12:20.427904300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_numerical_test2, X_categorical, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X_numerical = torch.Tensor(X_numerical_test2)\n",
    "        self.X_categorical = torch.Tensor(X_categorical)\n",
    "        self.y = torch.Tensor(y)\n",
    " \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.y)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        numerical_data = self.X_numerical[idx]\n",
    "        categorical_data = self.X_categorical[idx].long()\n",
    "        target = self.y[idx]\n",
    "        return numerical_data, categorical_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "18cfcf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up DataLoader for data set\n",
    "dataset = CustomDataset(X_numerical_test2, X_categorical, data_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b680d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set, val_set = train_test_split(dataset, test_size = 0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c5436c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87459\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b0d4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set, test_set = train_test_split(val_set, test_size = 0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9aa4f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10932\n",
      "10933\n"
     ]
    }
   ],
   "source": [
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "49aae55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T09:13:20.654212100Z",
     "start_time": "2023-11-09T09:13:20.621214500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=50, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=50, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "32ccfd37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T09:16:01.271922900Z",
     "start_time": "2023-11-09T09:16:01.239922900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750\n",
      "219\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191c837",
   "metadata": {},
   "source": [
    "for batch_idx, (X_num_batch, X_cat_batch, y_batch) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"X_num_batch.shape: {X_num_batch.shape}\")\n",
    "    print(f\"X_cat_batch.shape: {X_cat_batch.shape}\")\n",
    "    print(f\"y_batch.shape: {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6214b7c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T09:17:12.752970200Z",
     "start_time": "2023-11-09T09:17:12.688552Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ModulationCNN(nn.Module):\n",
    "    def __init__(self, num_numerical_features, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        #self.embeddings = nn.ModuleList([nn.Embedding(num, emb_dim) for num, emb_dim in zip(num_categories, emb_dims)])\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num, emb_dim) for num, emb_dim in embedding_size])\n",
    "        #self.embeddings = nn.ModuleList([nn.Embedding(num, emb_dim) for num, emb_dim in zip(num_categories, embedding_size)])\n",
    "\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_features\n",
    "        \n",
    "        # Now define the fully connected layers using self.fc1_input_size\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=48, kernel_size=2, stride=2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(48)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=48, out_channels=48, kernel_size=2, stride=2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(48)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=48, out_channels=24, kernel_size=1, stride=1)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(24)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(1320, 120)\n",
    "        self.batchnorm_fc1 = nn.BatchNorm1d(120)\n",
    "        \n",
    "        self.fc2 = nn.Linear(120, 6)\n",
    "\n",
    "        self.batch_norm_num = nn.BatchNorm1d(204)\n",
    "        self.af = nn.ReLU()\n",
    "        self.af_out = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X_numerical, X_categorical):\n",
    "        embeddings = []\n",
    "        \n",
    "        for i, e in enumerate(self.embeddings):\n",
    "            #print(self.embeddings)\n",
    "            #print(X_categorical)\n",
    "            \n",
    "            embeddings.append(e(X_categorical[:,i].int()))\n",
    "            x = torch.cat(embeddings, 1)\n",
    "        \n",
    "        X_numerical = self.batch_norm_num(X_numerical)\n",
    "        x = torch.cat([x.unsqueeze(2), X_numerical.unsqueeze(2)], 1)\n",
    "        \n",
    "        x = self.conv1(x.permute(0,2,1))\n",
    "        #x = self.af(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = self.af(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.conv3(x)\n",
    "        #x = self.af(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        #x = self.af(x)\n",
    "        x = self.batchnorm_fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.af_out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "90725a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_numerical_features = X_numerical.shape[1]\n",
    "#num_categories = [2, 4, 4, 2]\n",
    "#num_categories = [len(set(col)) for col in X_categorical.T]\n",
    "#emb_dim = [2, 2, 2, 2]\n",
    "#embedding_size = [5, 5, 5, 5]\n",
    "embedding_size = [(3, 4), (4, 4), (4, 4), (3, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3bd1e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModulationCNN(num_numerical_features, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c75d0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f83b3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "l1_lambda = 0.005\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "355e8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "\n",
    "val_loss_hist = []\n",
    "val_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "15def4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109324, 204)\n"
     ]
    }
   ],
   "source": [
    "print(X_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Training Loss: 1.7931 Training accuracy: 17.04%: : 1750it [00:56, 30.72it/s]\n",
      "Epoch [1/100] Validation Loss: 1.7934 Validation accuracy: 16.51%: : 219it [00:02, 101.11it/s]\n",
      "Epoch [2/100] Training Loss: 1.7926 Training accuracy: 16.81%: : 423it [00:14, 60.52it/s]"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # set model in training mode and run through each batch\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    running_train_acc = 0\n",
    "    progress_bar_train = tqdm(enumerate(train_loader))\n",
    "    for index, (X_batch_num_train, X_batch_cat_train, y_batch_train) in progress_bar_train:\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        y_pred_train = model(X_batch_num_train, X_batch_cat_train)\n",
    "        \n",
    "        \"\"\"\n",
    "        l1_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.abs(param).sum()\n",
    "        loss_train = loss_fn(y_pred_train, y_batch_train) + l1_lambda*l1_reg\n",
    "        \"\"\"\n",
    "        loss_train = loss_fn(y_pred_train, y_batch_train)\n",
    "        running_train_loss += loss_train.item()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute accuracy metrics\n",
    "        correct_pred_train = (torch.argmax(y_pred_train, 1) == torch.argmax(y_batch_train, 1)).float()\n",
    "        acc_train = correct_pred_train.sum() / len(correct_pred_train)\n",
    "        running_train_acc += acc_train\n",
    "         \n",
    "        \n",
    "        progress_bar_train.set_description(f'Epoch [{epoch+1}/{n_epochs}] Training Loss: {running_train_loss/(index+1):.4f} Training accuracy: {(running_train_acc/(index+1))*100:.2f}%')\n",
    "    \n",
    "     # store metrics\n",
    "    train_loss_hist.append(running_train_loss/(index+1))\n",
    "    train_acc_hist.append(running_train_acc/(index+1))\n",
    "    \n",
    "    model.eval()\n",
    "    running_val_loss = 0\n",
    "    running_val_acc = 0\n",
    "    progress_bar_val = tqdm(enumerate(val_loader)) \n",
    "    for index, (X_batch_num_val, y_batch_num_val, y_batch_val) in progress_bar_val:\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(X_batch_num_val, y_batch_num_val)\n",
    "            val_test = loss_fn(y_pred_val, y_batch_val)\n",
    "            running_val_loss += val_test.item()\n",
    "            \n",
    "            # Calculate accuracy metric\n",
    "            correct_pred_val = (torch.argmax(y_pred_val, 1) == torch.argmax(y_batch_val, 1)).float()\n",
    "            acc_val = correct_pred_val.sum() / len(correct_pred_val)\n",
    "            running_val_acc += acc_val\n",
    "            \n",
    "            progress_bar_val.set_description(f'Epoch [{epoch+1}/{n_epochs}] Validation Loss: {running_val_loss/(index+1):.4f} Validation accuracy: {(running_val_acc/(index+1))*100:.2f}%')\n",
    "        \n",
    "    val_loss_hist.append(running_val_loss/(index+1))\n",
    "    val_acc_hist.append(running_val_acc/(index+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbee97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:53:10.090458Z",
     "start_time": "2023-11-09T02:53:07.982212900Z"
    }
   },
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Pass the test data through the model\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        test_outputs = model(inputs)\n",
    "\n",
    "        # Convert the model outputs to predicted classes\n",
    "        predicted_classes = torch.argmax(test_outputs, dim=1)\n",
    "\n",
    "        # Update correct and total predictions counters\n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d455942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T09:00:58.951463900Z",
     "start_time": "2023-11-09T09:00:58.930432100Z"
    }
   },
   "outputs": [],
   "source": [
    "#1. calculate the right ACC\n",
    "#2. shuffle the order of batch?\n",
    "#3. loss function\n",
    "#4. activation function: softmax for outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4728c7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T23:02:19.428802500Z",
     "start_time": "2023-10-25T23:02:19.423765100Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove pooli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefc75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T19:36:37.205303800Z",
     "start_time": "2023-10-25T19:36:37.162931300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f6299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
