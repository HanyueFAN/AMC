{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd38475c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T08:29:40.021842700Z",
     "start_time": "2023-10-18T08:29:35.369618600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "100bad1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:05:52.641698600Z",
     "start_time": "2023-10-17T19:05:52.631606800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = 'F:\\ISEP_Learning_Document\\Semester3\\End-of-track Project\\dataset\\data_raw\\GOLD_XYZ_OSC.0001_1024.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbf6d77b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:05:53.230761700Z",
     "start_time": "2023-10-17T19:05:53.205262300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Open my file in read mode\n",
    "file_raw = h5py.File(file_path,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6856bedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:07:39.098601700Z",
     "start_time": "2023-10-17T19:05:53.947344300Z"
    }
   },
   "outputs": [],
   "source": [
    "#access the datasets within the HDF5 File\n",
    "data_raw_x = file_raw['X'][:]\n",
    "data_raw_y = file_raw['Y'][:]\n",
    "data_raw_z = file_raw['Z'][:]\n",
    "\n",
    "#reduce the dataset to 10%\n",
    "# Calculate the new reduced size (10% of the original)\n",
    "new_size = int(len(data_raw_x) * 0.10)\n",
    "\n",
    "# Generate random indines to maintain the corresponding relationships\n",
    "randon_indices = torch.randperm(len(data_raw_x))[:new_size]\n",
    "# Use the random indices to create reduced data\n",
    "data_raw_x_reduced = data_raw_x[randon_indices]\n",
    "data_raw_y_reduced = data_raw_y[randon_indices]\n",
    "data_raw_z_reduced = data_raw_z[randon_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "322a1c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:07:44.876313900Z",
     "start_time": "2023-10-17T19:07:44.817449300Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Convert the hdf5 dataset to a PyTorch tensor\n",
    "# X_tensor = torch.from_numpy(data_raw_x).float()\n",
    "# Y_tensor = torch.from_numpy(data_raw_y).long()\n",
    "# Z_tensor = torch.from_numpy(data_raw_z).long()\n",
    "\n",
    "# Convert the hdf5 dataset to a PyTorch tensor\n",
    "X_tensor = torch.from_numpy(data_raw_x_reduced).float()\n",
    "Y_tensor = torch.from_numpy(data_raw_y_reduced).long()\n",
    "Z_tensor = torch.from_numpy(data_raw_z_reduced).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd79bbba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:07:49.921331400Z",
     "start_time": "2023-10-17T19:07:48.623267700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of samples in your dataset\n",
    "num_samples = X_tensor.size(0)\n",
    "\n",
    "# Create a random permutation of indices\n",
    "random_indices = torch.randperm(num_samples)\n",
    "\n",
    "# Use these indices to shuffle your data tensors\n",
    "X_tensor = X_tensor[random_indices]\n",
    "Y_tensor = Y_tensor[random_indices]\n",
    "Z_tensor = Z_tensor[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdde8842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T18:59:06.552871700Z",
     "start_time": "2023-10-17T18:59:06.504734600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([255590, 1024, 2])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b8a8370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:13:52.616063700Z",
     "start_time": "2023-10-17T19:13:49.287723600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize X_tensor\n",
    "# Define the batch size for normalization (64 in your case)\n",
    "batch_size = 64\n",
    "\n",
    "# Calculate the number of batches needed\n",
    "num_samples = X_tensor.size(0)\n",
    "num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "# Create a list to store the normalized batches\n",
    "normalized_batches = []\n",
    "\n",
    "# Normalize the data in batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, num_samples)\n",
    "    batch = X_tensor[start_idx:end_idx]\n",
    "\n",
    "    # Calculate batch statistics for normalization\n",
    "    batch_mean = batch.mean(dim=0)\n",
    "    batch_std = batch.std(dim=0)\n",
    "\n",
    "    # Normalize the batch using z-score\n",
    "    normalized_batch = (batch - batch_mean) / batch_std\n",
    "\n",
    "    # Append the normalized batch to the list\n",
    "    normalized_batches.append(normalized_batch)\n",
    "\n",
    "# Stack the normalized batches back together\n",
    "X_tensor = torch.cat(normalized_batches, dim=0)\n",
    "\n",
    "# Verify that the number of samples remains the same\n",
    "assert X_tensor.size(0) == num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba961cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:13:54.630414300Z",
     "start_time": "2023-10-17T19:13:54.608552400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([255590, 1024, 2])\n"
     ]
    }
   ],
   "source": [
    "# Get the shape (dimensions) of the data\n",
    "print(f\"Data shape: {X_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7025b692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:08:31.068605400Z",
     "start_time": "2023-10-17T19:08:31.029228600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Dataset_X Information:\n",
      "--------------------------\n",
      "Data type: torch.FloatTensor\n",
      "Data shape: torch.Size([255590, 1024, 2])\n",
      "Number of elements: 523448320\n",
      "First few data elements:\n",
      "tensor([[[-0.7612, -0.3999],\n",
      "         [-0.6185, -0.2538],\n",
      "         [-0.4491, -0.0794],\n",
      "         ...,\n",
      "         [ 1.0775, -0.3634],\n",
      "         [ 1.0933, -0.1532],\n",
      "         [ 1.0393,  0.1003]],\n",
      "\n",
      "        [[-0.8685,  1.8274],\n",
      "         [-0.8667,  1.8291],\n",
      "         [-0.8567,  1.7947],\n",
      "         ...,\n",
      "         [-0.0370,  0.0729],\n",
      "         [-0.0976,  0.2178],\n",
      "         [-0.1691,  0.3761]],\n",
      "\n",
      "        [[ 0.5914,  0.1220],\n",
      "         [ 0.8038, -0.8054],\n",
      "         [ 0.3615, -0.1006],\n",
      "         ...,\n",
      "         [-2.1932, -0.3773],\n",
      "         [ 0.1929,  0.3938],\n",
      "         [-0.4551,  0.0800]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.2323, -7.5590],\n",
      "         [ 6.3631, -7.6909],\n",
      "         [ 6.5043, -7.8581],\n",
      "         ...,\n",
      "         [ 7.0595, -6.4770],\n",
      "         [ 7.0548, -6.4728],\n",
      "         [ 7.0475, -6.4839]],\n",
      "\n",
      "        [[-0.1001,  0.3447],\n",
      "         [-0.0796,  0.4774],\n",
      "         [ 1.1469, -0.8190],\n",
      "         ...,\n",
      "         [-0.9650, -0.6339],\n",
      "         [-0.6496, -0.5849],\n",
      "         [ 0.0444,  0.4762]],\n",
      "\n",
      "        [[ 1.2323,  0.6131],\n",
      "         [ 1.1729,  0.6062],\n",
      "         [ 1.0733,  0.6102],\n",
      "         ...,\n",
      "         [-0.8855,  0.1190],\n",
      "         [-0.8395,  0.2343],\n",
      "         [-0.7257,  0.3568]]])\n"
     ]
    }
   ],
   "source": [
    "# Inspect attributes and basic information\n",
    "print(\"Tensor Dataset_X Information:\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "# Check the data type of the tensor dataset\n",
    "print(f\"Data type: {X_tensor.type()}\")\n",
    "\n",
    "# Get the shape (dimensions) of the data\n",
    "print(f\"Data shape: {X_tensor.shape}\")\n",
    "\n",
    "# Check the number of elements in the dataset\n",
    "print(f\"Number of elements: {X_tensor.numel()}\")\n",
    "\n",
    "# Access the first few elements of the data\n",
    "print(\"First few data elements:\")\n",
    "print(X_tensor[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3740a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:08:31.674004600Z",
     "start_time": "2023-10-17T19:08:31.653828300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Dataset_Y Information:\n",
      "--------------------------\n",
      "Data type: torch.LongTensor\n",
      "Data shape: torch.Size([255590, 24])\n",
      "Number of elements: 6134160\n",
      "First few data elements:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Inspect attributes and basic information\n",
    "print(\"Tensor Dataset_Y Information:\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "# Check the data type of the tensor dataset\n",
    "print(f\"Data type: {Y_tensor.type()}\")\n",
    "\n",
    "# Get the shape (dimensions) of the data\n",
    "print(f\"Data shape: {Y_tensor.shape}\")\n",
    "\n",
    "# Check the number of elements in the dataset\n",
    "print(f\"Number of elements: {Y_tensor.numel()}\")\n",
    "\n",
    "# Access the first few elements of the data\n",
    "print(\"First few data elements:\")\n",
    "print(Y_tensor[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d62f22b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:08:32.046022800Z",
     "start_time": "2023-10-17T19:08:32.017533400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Dataset_Z Information:\n",
      "--------------------------\n",
      "Data type: torch.LongTensor\n",
      "Data shape: torch.Size([255590, 1])\n",
      "Number of elements: 255590\n",
      "First few data elements:\n",
      "tensor([[ 30],\n",
      "        [ 26],\n",
      "        [-18],\n",
      "        [  2],\n",
      "        [ 26],\n",
      "        [ 16],\n",
      "        [ 16],\n",
      "        [ 30],\n",
      "        [ -6],\n",
      "        [ 22],\n",
      "        [-12],\n",
      "        [ -6],\n",
      "        [ 28],\n",
      "        [ 12],\n",
      "        [ 16],\n",
      "        [ -4],\n",
      "        [-10],\n",
      "        [ 20],\n",
      "        [-20],\n",
      "        [ 20],\n",
      "        [ 18],\n",
      "        [ 28],\n",
      "        [ 18],\n",
      "        [-10],\n",
      "        [-20],\n",
      "        [-12],\n",
      "        [-20],\n",
      "        [ 26],\n",
      "        [ 12],\n",
      "        [ -4],\n",
      "        [ 26],\n",
      "        [ 24],\n",
      "        [ 18],\n",
      "        [ 10],\n",
      "        [ 20],\n",
      "        [ 26],\n",
      "        [ 10],\n",
      "        [ -8],\n",
      "        [ 30],\n",
      "        [ 30],\n",
      "        [ 20],\n",
      "        [  4],\n",
      "        [  0],\n",
      "        [-10],\n",
      "        [ 18],\n",
      "        [  0],\n",
      "        [-10],\n",
      "        [ 24],\n",
      "        [ 30],\n",
      "        [-10]])\n"
     ]
    }
   ],
   "source": [
    "# Inspect attributes and basic information\n",
    "print(\"Tensor Dataset_Z Information:\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "# Check the data type of the tensor dataset\n",
    "print(f\"Data type: {Z_tensor.type()}\")\n",
    "\n",
    "# Get the shape (dimensions) of the data\n",
    "print(f\"Data shape: {Z_tensor.shape}\")\n",
    "\n",
    "# Check the number of elements in the dataset\n",
    "print(f\"Number of elements: {Z_tensor.numel()}\")\n",
    "\n",
    "# Access the first few elements of the data\n",
    "print(\"First few data elements:\")\n",
    "print(Z_tensor[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6335e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T19:08:32.566367800Z",
     "start_time": "2023-10-17T19:08:32.427619400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine X_tensor, Y_tensor, Z_tensor into a single dataset\n",
    "dataset = TensorDataset(X_tensor, Y_tensor, Z_tensor)\n",
    "\n",
    "# Calculate the sizes of training, validation, and test sets.\n",
    "total_size = len(X_tensor)\n",
    "\n",
    "train_size = int(total_size * 0.6)\n",
    "val_size = int(total_size * 0.2)\n",
    "test_size = total_size - train_size -val_size\n",
    "\n",
    "#split the dataset\n",
    "train_dataset = dataset[:train_size]\n",
    "val_dataset = dataset[train_size:train_size + val_size]\n",
    "test_dataset = dataset[train_size+val_size:]\n",
    "\n",
    "#Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "#Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle= False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle= False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d725feec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been shrunk to 1% of its original size and saved to F:\\ISEP_Learning_Document\\Semester3\\End-of-track Project\\dataset\\data_raw\\demo.hdf5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Input file path (replace with your file path)\n",
    "input_file_path = 'F:\\ISEP_Learning_Document\\Semester3\\End-of-track Project\\dataset\\data_raw\\GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "\n",
    "# Output file path (replace with your desired output file path)\n",
    "output_file_path = 'F:\\ISEP_Learning_Document\\Semester3\\End-of-track Project\\dataset\\data_raw\\demo.hdf5'\n",
    "\n",
    "# Open the input HDF5 file in read mode\n",
    "with h5py.File(input_file_path, 'r') as input_file:\n",
    "    # Create a new HDF5 file in write mode for the output\n",
    "    with h5py.File(output_file_path, 'w') as output_file:\n",
    "        # Iterate through the datasets in the input file\n",
    "        for dataset_name, dataset in input_file.items():\n",
    "            # Determine the desired dataset shape for shrinking to 1% of the original size\n",
    "            new_shape = tuple(int(dim * 0.01) if i != 0 else dim for i, dim in enumerate(dataset.shape))\n",
    "\n",
    "            # Create a new dataset in the output file with the new shape and data type\n",
    "            output_dataset = output_file.create_dataset(dataset_name, shape=new_shape, dtype=dataset.dtype)\n",
    "\n",
    "            # Copy data from the input dataset to the output dataset\n",
    "            output_dataset[...] = dataset[...]\n",
    "\n",
    "print(\"Dataset has been shrunk to 1% of its original size and saved to\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95021b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modulation",
   "language": "python",
   "name": "modulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
